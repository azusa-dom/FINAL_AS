import pandas as pd
import numpy as np
import argparse
import osÆ’
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import StratifiedKFold
from imblearn.over_sampling import SMOTE
from sklearn.pipeline import Pipeline
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer


def create_preprocessor(numeric_features, categorical_features):
    """
    æ ¹æ®ç‰¹å¾ç±»å‹ï¼Œåˆ›å»ºä¸€ä¸ªscikit-learné¢„å¤„ç†å™¨ã€‚
    è¿™ä¸ªé¢„å¤„ç†å™¨åŒ…å«äº†å¯¹æ•°å€¼å’Œåˆ†ç±»ç‰¹å¾çš„ç‹¬ç«‹å¤„ç†æµç¨‹ã€‚
    """
    # ä¸ºæ•°å€¼ç‰¹å¾åˆ›å»ºå¤„ç†ç®¡é“ï¼š1. å‡å€¼å¡«å…… -> 2. æ ‡å‡†åŒ–
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])

    # ä¸ºåˆ†ç±»ç‰¹å¾åˆ›å»ºå¤„ç†ç®¡é“ï¼š1. ä¼—æ•°å¡«å…… -> 2. One-Hotç¼–ç 
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    # ä½¿ç”¨ColumnTransformerå°†ä¸Šè¿°ä¸¤ç§ç®¡é“ç»„åˆèµ·æ¥
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='passthrough' # ä¿ç•™å…¶ä»–æœªæŒ‡å®šå¤„ç†çš„åˆ—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    )
    
    return preprocessor

def process_and_save_folds(input_csv, output_dir, n_splits=5, id_column='patient_id', label_column='label'):
    """
    ä¸»å‡½æ•°ï¼šåŠ è½½æ•°æ®ï¼Œæ‰§è¡ŒK-æŠ˜äº¤å‰éªŒè¯åˆ’åˆ†ï¼Œå¹¶åœ¨æ¯ä¸€æŠ˜ä¸­å¤„ç†æ•°æ®ä»¥é˜²æ­¢æ³„æ¼ï¼Œæœ€åä¿å­˜ç»“æœã€‚
    """
    print(f"ğŸ“¥ æ­£åœ¨è¯»å–ä¸´åºŠæ•°æ®: {input_csv}")
    df = pd.read_csv(input_csv)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    # é¢„å¤„ç†ï¼šç§»é™¤ä¸åˆé€»è¾‘çš„æ•°æ® (ä¾‹å¦‚)
    if 'age' in df.columns:
        initial_rows = len(df)
        df = df[df['age'] >= 0]
        if initial_rows > len(df):
            print(f"âœ… å·²ç§»é™¤ {initial_rows - len(df)} è¡Œè´Ÿæ•°å¹´é¾„çš„æ•°æ®ã€‚")

    # åˆ†ç¦»ç‰¹å¾(X)å’Œæ ‡ç­¾(y)ï¼ŒIDåˆ—ä¸ä½œä¸ºç‰¹å¾
    y = df[label_column]
    X = df.drop(columns=[label_column, id_column], errors='ignore')

    # è¯†åˆ«ç‰¹å¾ç±»å‹
    numeric_features = X.select_dtypes(include=np.number).columns.tolist()
    categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()
    print(f"ğŸ” è¯†åˆ«å‡ºçš„æ•°å€¼ç‰¹å¾: {numeric_features}")
    print(f"ğŸ” è¯†åˆ«å‡ºçš„åˆ†ç±»ç‰¹å¾: {categorical_features}")

    # åˆå§‹åŒ–K-æŠ˜äº¤å‰éªŒè¯
    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    print(f"\n--- å¼€å§‹å¤„ç† {n_splits}-æŠ˜ äº¤å‰éªŒè¯æ•°æ® ---")

    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):
        print(f"\nâš™ï¸ æ­£åœ¨å¤„ç† Fold {fold}...")
        
        # åˆ’åˆ†å½“å‰æŠ˜çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        # 1. åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = create_preprocessor(numeric_features, categorical_features)

        # 2. **å…³é”®æ­¥éª¤**: åªåœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆé¢„å¤„ç†å™¨
        preprocessor.fit(X_train)
        
        # è·å– one-hot ç¼–ç åçš„æ–°ç‰¹å¾å
        try:
            ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
            new_feature_names = numeric_features + ohe_feature_names.tolist()
        except Exception:
            new_feature_names = numeric_features # å¦‚æœæ²¡æœ‰åˆ†ç±»ç‰¹å¾ï¼Œåˆ™ä¿æŒä¸å˜

        # 3. ä½¿ç”¨å·²æ‹Ÿåˆçš„é¢„å¤„ç†å™¨è½¬æ¢è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train_processed = preprocessor.transform(X_train)
        X_val_processed = preprocessor.transform(X_val)
        
        # 4. **å…³é”®æ­¥éª¤**: åªå¯¹å¤„ç†åçš„è®­ç»ƒæ•°æ®è¿›è¡ŒSMOTEè¿‡é‡‡æ ·
        smote = SMOTE(random_state=42)
        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)
        print(f"  SMOTE è¿‡é‡‡æ ·å®Œæˆ, è®­ç»ƒæ ·æœ¬ä» {len(X_train)} å¢åŠ åˆ° {len(X_train_resampled)}")

        # 5. å°†å¤„ç†åçš„æ•°æ®è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
        df_X_train = pd.DataFrame(X_train_resampled, columns=new_feature_names)
        df_y_train = pd.DataFrame(y_train_resampled, columns=[label_column])
        df_X_val = pd.DataFrame(X_val_processed, columns=new_feature_names)
        df_y_val = pd.DataFrame(y_val.values, columns=[label_column])

        # å®šä¹‰ä¿å­˜è·¯å¾„
        train_path = os.path.join(output_dir, f"fold_{fold}_train.csv")
        val_path = os.path.join(output_dir, f"fold_{fold}_val.csv")

        # åˆå¹¶ç‰¹å¾å’Œæ ‡ç­¾åä¿å­˜
        pd.concat([df_X_train, df_y_train], axis=1).to_csv(train_path, index=False)
        pd.concat([df_X_val, df_y_val], axis=1).to_csv(val_path, index=False)
        
        print(f"  âœ… å·²ä¿å­˜ Fold {fold} çš„å¤„ç†åæ•°æ®:")
        print(f"    -> è®­ç»ƒé›†: {train_path}")
        print(f"    -> éªŒè¯é›†: {val_path}")

    print("\nğŸ‰ å…¨éƒ¨æ•°æ®å¤„ç†å’Œåˆ’åˆ†å®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä¸´åºŠæ•°æ®é¢„å¤„ç†è„šæœ¬ï¼Œç”¨äºäº¤å‰éªŒè¯ï¼Œå¯é˜²æ­¢æ•°æ®æ³„æ¼ã€‚")
    parser.add_argument("input_csv", help="åŸå§‹ä¸´åºŠæ•°æ® CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("output_dir", help="ä¿å­˜å¤„ç†åå„æŠ˜æ•°æ®æ–‡ä»¶çš„ç›®å½•")
    parser.add_argument("--n_splits", type=int, default=5, help="äº¤å‰éªŒè¯çš„æŠ˜æ•°ï¼Œé»˜è®¤ä¸º 5")
    parser.add_argument("--id_column", default="patient_id", help="æ‚£è€…IDåˆ—åï¼Œæ­¤åˆ—ä¸ä½œä¸ºç‰¹å¾")
    parser.add_argument("--label_column", default="label", help="æ ‡ç­¾åˆ—å")
    
    args = parser.parse_args()

    process_and_save_folds(
        args.input_csv,
        args.output_dir,
        n_splits=args.n_splits,
        id_column=args.id_column,
        label_column=args.label_column
    )
