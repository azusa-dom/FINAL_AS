import argparse
import os
import shap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

def plot_shap_summary(model, X_test, feature_names, save_dir):
    """
    æ ¹æ®å·²è®­ç»ƒçš„æ¨¡å‹å’Œæµ‹è¯•æ•°æ®ç”Ÿæˆå¹¶ä¿å­˜SHAPæ‘˜è¦å›¾ã€‚
    
    Args:
        model: ä»»ä½•ä¸SHAPå…¼å®¹çš„å·²è®­ç»ƒæ¨¡å‹å¯¹è±¡ã€‚
        X_test (pd.DataFrame or np.ndarray): ç”¨äºè§£é‡Šçš„æµ‹è¯•ç‰¹å¾æ•°æ®ã€‚
        feature_names (list): ç‰¹å¾åç§°åˆ—è¡¨ã€‚
        save_dir (str): ä¿å­˜å›¾åƒçš„ç›®å½•ã€‚
    """
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆ SHAP å›¾...")
    # åˆ›å»ºä¸€ä¸ªè§£é‡Šå™¨
    # å¯¹äºæ ‘æ¨¡å‹ï¼ˆå¦‚XGBoostï¼‰ï¼Œä½¿ç”¨ shap.TreeExplainer ä¼šæ›´å¿«
    if hasattr(model, 'predict_proba'):
        explainer = shap.KernelExplainer(model.predict_proba, X_test)
    else:
        explainer = shap.KernelExplainer(model.predict, X_test)

    # è®¡ç®—SHAPå€¼
    shap_values = explainer.shap_values(X_test)

    # ç¡®ä¿ X_test æ˜¯ä¸€ä¸ªDataFrameä»¥ä¾¿æ­£ç¡®æ˜¾ç¤ºç‰¹å¾åç§°
    if not isinstance(X_test, pd.DataFrame):
        X_test_df = pd.DataFrame(X_test, columns=feature_names)
    else:
        X_test_df = X_test

    # ç»˜åˆ¶æ‘˜è¦å›¾ï¼ˆbeeswarm plotæ›´å…·ä¿¡æ¯é‡ï¼‰
    plt.figure()
    # å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œé€šå¸¸æˆ‘ä»¬åªå…³å¿ƒæ­£ç±»çš„SHAPå€¼
    shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, X_test_df, show=False)
    plt.title("SHAP Summary Plot")
    plt.tight_layout()
    save_path = os.path.join(save_dir, "shap_summary_plot.png")
    plt.savefig(save_path)
    plt.close()
    print(f"âœ… SHAP å›¾å·²ä¿å­˜ â†’ {save_path}")


def plot_decision_curve(y_true, y_pred_probs, save_dir):
    """
    æ ¹æ®çœŸå®æ ‡ç­¾å’Œæ¨¡å‹é¢„æµ‹æ¦‚ç‡ç”Ÿæˆå¹¶ä¿å­˜å†³ç­–æ›²çº¿åˆ†æå›¾ã€‚

    Args:
        y_true (np.ndarray): çœŸå®æ ‡ç­¾ (0 æˆ– 1)ã€‚
        y_pred_probs (np.ndarray): æ¨¡å‹å¯¹æ­£ç±»çš„é¢„æµ‹æ¦‚ç‡ã€‚
        save_dir (str): ä¿å­˜å›¾åƒçš„ç›®å½•ã€‚
    """
    print("ğŸ“ˆ æ­£åœ¨ç”Ÿæˆ DCA æ›²çº¿å›¾...")
    thresholds = np.linspace(0.01, 0.99, 100)
    net_benefit_model = []
    
    # è®¡ç®—æ¨¡å‹çš„å‡€è·ç›Š
    for t in thresholds:
        y_pred = (y_pred_probs >= t).astype(int)
        n = len(y_true)
        tp = np.sum((y_pred == 1) & (y_true == 1))
        fp = np.sum((y_pred == 1) & (y_true == 0))
        net_benefit_model.append((tp / n) - (fp / n) * (t / (1 - t)))

    # è®¡ç®— "Treat All" å’Œ "Treat None" ç­–ç•¥çš„å‡€è·ç›Š
    p_all = np.mean(y_true)
    net_benefit_all = p_all - (1 - p_all) * (thresholds / (1 - thresholds))
    net_benefit_none = np.zeros_like(thresholds)

    # ç»˜å›¾
    plt.figure(figsize=(8, 6))
    plt.plot(thresholds, net_benefit_model, label="Model", color="crimson")
    plt.plot(thresholds, net_benefit_all, label="Treat All", linestyle="--", color="black")
    plt.plot(thresholds, net_benefit_none, label="Treat None", linestyle=":", color="gray")
    plt.ylim(min(np.nanmin(net_benefit_model), -0.1), max(np.nanmax(net_benefit_model), np.nanmax(net_benefit_all), 0.5))
    plt.xlabel("Threshold Probability")
    plt.ylabel("Net Benefit")
    plt.title("Decision Curve Analysis (DCA)")
    plt.grid(alpha=0.4)
    plt.legend()
    plt.tight_layout()
    save_path = os.path.join(save_dir, "dca_curve.png")
    plt.savefig(save_path)
    plt.close()
    print(f"âœ… DCA å›¾å·²ä¿å­˜ â†’ {save_path}")

if __name__ == "__main__":
    # --- è¿™æ˜¯ä¸€ä¸ªå¦‚ä½•ä½¿ç”¨è¿™äº›å‡½æ•°çš„æ¼”ç¤º ---
    print("--- å¼€å§‹ç»˜å›¾è„šæœ¬æ¼”ç¤º ---")
    
    # 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®å’Œæ¨¡å‹ (åœ¨æ‚¨çš„çœŸå®ä»£ç ä¸­ï¼Œæ‚¨ä¼šåŠ è½½è¿™äº›)
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)
    feature_names = [f'feature_{i}' for i in range(X.shape[1])]
    X_df = pd.DataFrame(X, columns=feature_names)
    
    X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.3, random_state=42, stratify=y)
    
    # å‡è®¾è¿™æ˜¯ä¸€ä¸ªæ‚¨å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹
    print("æ­£åœ¨è®­ç»ƒä¸€ä¸ªæ¨¡æ‹Ÿæ¨¡å‹...")
    # model = YourFusionModel().fit(X_train, y_train) 
    model = LogisticRegression().fit(X_train, y_train)
    print("æ¨¡æ‹Ÿæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

    # 2. æŒ‡å®šä¿å­˜ç›®å½•
    save_directory = "results_plots_demo"
    os.makedirs(save_directory, exist_ok=True)

    # 3. è°ƒç”¨ç»˜å›¾å‡½æ•°
    # è·å–æµ‹è¯•é›†çš„é¢„æµ‹æ¦‚ç‡ç”¨äºDCA
    test_probabilities = model.predict_proba(X_test)[:, 1]

    # ç”Ÿæˆ SHAP å›¾
    # æ³¨æ„ï¼šå¯¹äºå¤§æ•°æ®é›†ï¼ŒSHAPå¯èƒ½å¾ˆæ…¢ï¼Œå¯ä»¥å¯¹X_testè¿›è¡Œé‡‡æ ·
    plot_shap_summary(model, X_test, feature_names, save_directory)

    # ç”Ÿæˆ DCA å›¾
    plot_decision_curve(y_test, test_probabilities, save_directory)

    print("\nâœ… ç»˜å›¾æ¼”ç¤ºå®Œæˆã€‚")

